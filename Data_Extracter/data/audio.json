[
  {
    "time": "2025-01-31 18:22:06",
    "text": " Dario Amade, former employee at OpenAI and current CEO and founder of Anthropik has dropped a new essay in which he details his thoughts on DeepSeq model innovation and GPU export controls to China. This combined with new evidence that shows DeepSeq may have actually distilled a lot of the data from OpenAI's models is causing a stir in the AI industry. Let me break it all down. So here's his new essay and it is incredible. Now before we get to this, I want to show you a few of the rumors and possible evidence that DeepSeq actually stole data from OpenAI to create the R1 model. So first in this Axios article, OpenAI says DeepSeq may have inappropriately used its models output. Now may have is not a strong statement. They're not saying definitely did. But at the same time, there was evidence in the fact that the DeepSeq R1 model itself says it was trained by OpenAI. Here's an example posted to the OpenAI subreddit right here. I was developed by OpenAI, a company founded in December 2015 by Sam Altman, Elon Musk, Greg Brockman, Ilya Suskover and so on. And so I've seen a few of these instances in which DeepSeq just says it was trained by OpenAI. Now that doesn't necessarily make it true. Obviously models hallucinate all the time and there could be a number of reasons that DeepSeq R1 has said this, but it is interesting. Let me show you a couple of the things. Now this is Jonathan Ross. CEO and founder of GROC. He specifically talks about how distillation works. And if you're not familiar with distillation, it is basically a small model learning from a big model. That is the most simplistic way to put it. Let's hear how Jonathan Ross explains what might have happened. If there's a really good model already right here, just have it generate the data and you go right up to where it is. And that's what they did. So it is true that they spent about six million or whatever it was on the training. They spent a lot more distilling or scraping the OpenAI model. So a lot of the top people in the industry, and this is not just anthropic leaders, OpenAI leaders, this is GROC's leader. And GROC is an inference provider and they only work with open source models right now. So he has not incentivized in any way to say these things as far as I can tell. So what he's basically saying and what a lot of people are kind of triangulating around is that, first of all, the five million dollar number to train R1, maybe, but really they spent a ton more before that. And I'm going to get to that. Apparently they have 50,000 GPUs, but they spent a lot more on that in the research and development and they also spent a lot more than that in the actual scraping of OpenAI's models. And so what a lot of people are saying is it is distilled down from an OpenAI model. Now that isn't taking away some of the innovations that the DeepSeek team has made and the DeepSeek team seems to be legit. They seem to be very smart and genuine with their efforts to push frontier AI. But I just want to put all of this in context for you and report on the new findings that I'm seeing around the web. Now here's David Sacks, AI and CryptoZar for the United States, essentially saying the same thing. Let's watch. There's a technique in AI called distillation, which you're going to hear a lot about. And it's when one model learns from another model. Effectively, what happens is that the student model asked the parent model a lot of questions, just like a human would learn. But AIs can do this, asking millions of questions and they can essentially mimic the reasoning process that they learned from the parent model and they can kind of suck the knowledge out of the parent model. And there's substantial evidence that what DeepSeek did here is they distilled the knowledge out of OpenAI's models. And I don't think OpenAI is very happy about this. All right. So he is saying the same thing. Now let's get to the main reason we're here today, Dario's essay. So Dario says, my thoughts on China export controls and two possible futures. And you could probably start to guess what two futures he's referencing are. Thanks to the sponsor of this segment, Recraft. Recraft is an image generation and editing tool. You've probably heard of it if you've watched this channel at all. V3 model secures the number one spot on the hugging face leaderboards, surpassing mid journey and OpenAI's Dolly with an impressive 1152 E-Lo rating. This is huge because Hugging Face is the leading platform for evaluating text to image models. So it has some stiff competition, but it was still number one. So why is Recraft so powerful? Well, it thinks in design language, giving you full control over your visuals, which is not something other models can say. Photo realistic images, posters, complex scenes, Recraft can do it all in a stunning way. And for realistic images, they are truly all of them. Here's a QR code expected and the reaction of the markets dropping in video by 16% was a stunning overreaction. And by the way, I agree with that. That is insane that that happened and really shows that a lot of analysts and investors truly do not understand what's going on in artificial intelligence. So he starts with, I won't focus on whether deep seek is or isn't a threat to USAI companies like Anthropic, although I do believe many of the claims about their threat to USAI leadership are greatly overstated. Okay, so right out of the gate saying this whole thing was blown way out of proportion, but he does say export policies become even more existentially important than they were a week ago. Let me break that down for you. What do export controls actually do? What do they mean? Well, right now there are export controls, which make it illegal to export cutting edge GPUs and AI chips to China. Now the reason for that is we don't want China building out AI infrastructure that would eventually allow them to maybe reach AGI and ASI before that because at that point it's too late. Then we live in a unipolar world. China is the leader and really there's no catching up after that. And so these policies are put in place so China cannot get their hands on vast amounts of cutting edge GPUs, generally from NVIDIA, like the H100. But these export controls don't always work. At least there's some evidence that DeepSeek and China in general has some H100s and they do that through Shell companies. They do that through smuggling kind of crazy stuff to be honest. I'd love to cover that in more detail because it's interesting from a geopolitical standpoint, it's interesting from a technology standpoint and yeah, it just sounds like a movie. Now he goes on to talk about the three dynamics of artificial intelligence. If you've watched his channel at all, you've heard me talk about this quite a bit. Now remember, Dario worked at OpenAI for a while before starting Anthropic. So Dario and his Anthropic co-founders were among the first to document the scaling laws back when he was working at OpenAI. All else equal scaling up the training of AI systems leads to smoothly better results on a range of cognitive tasks across the board. Basically every order of magnitude increase in the scale of a training run or the amount of compute you're throwing at something, the smooth linear increase in quality you're going to see. So he gives some numbers. A million dollar model might solve 20% of important coding tasks. 10 million, so that's 10x, might solve 40%. A hundred million, that's a hundred x, might solve 60%. So exponential increase in spend, linear increase in quality. That is one of the scaling laws. These differences tend to have huge implications in practice. Another factor of 10 may correspond to the difference between an undergraduate and PhD skill level and thus companies are investing heavily in training these models. And that's the thing, they get exponentially more expensive to get these linear improvements. And so it really does take a crazy amount of money, a crazy amount of compute to actually squeeze out these improvements in quality. Next is the shifting curve. And here he talks about. Hi, I'm premium wireless for $15 a month at Mint Mobile. What I'm premium wireless for $15.00. About both on the software and architecture side and the hardware side improvements that provide huge jumps in efficiency and quality. So for example, it could be an improvement to the architecture of the model. A tweak to the basic transformer architecture. New generations of hardware also have the same effect. And so what you're seeing is these improvements in efficiency, these innovations could result in a 1.2 x improvement, a 2 x, a 4 x improvement. And so that is the shifting curve that he's referring to every frontier AI company regularly discovers many of these CMs. That's compute multipliers. Only small ones, 1.2 x, sometimes medium ones, 2 x and every once in a while, very large ones 10 x. I want to read this slowly because this is critically important. Listen to this. Because the value of having a more intelligent system is so high, this shifting of the curve typically causes companies to spend more, not less on training models. The gains in cost efficiency end up entirely devoted to training smarter models, limited only by the company's financial resources. So that is a mixture of Jevons paradox and just the nature of intelligence exploding right before our eyes. It's not that we're going to reach some plateau one day and companies are going to say, okay, we're done. No more training, no more inference needed. No, no, it's quite the opposite. Every time we have this huge unlock in terms of efficiency or cost reduction, all of the compute available continues to be used in full. It just goes towards whatever that next step up is. People are naturally attracted to the idea that first something is expensive, then it gets"
  }
]
